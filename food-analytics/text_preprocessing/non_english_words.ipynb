{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a42dc2-741e-4cb8-9210-0d4b610d0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas openpyxl nltk langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba40ab3-e962-4ef2-a1f8-7533035b67a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-English / Hindi-like words:\n",
      "achari\n",
      "afza\n",
      "ajinomoto\n",
      "ajwain\n",
      "almondette\n",
      "aloo\n",
      "amchur\n",
      "amul\n",
      "ararot\n",
      "arbi\n",
      "asafoetida\n",
      "baati\n",
      "bafla\n",
      "baingan\n",
      "barfi\n",
      "basmati\n",
      "bathua\n",
      "bhaji\n",
      "bhajji\n",
      "bharta\n",
      "bhatura\n",
      "bhindi\n",
      "bhujia\n",
      "bhujiya\n",
      "bhurji\n",
      "biryani\n",
      "boondi\n",
      "bundi\n",
      "bura\n",
      "chaap\n",
      "chaat\n",
      "chakli\n",
      "chana\n",
      "chane\n",
      "chapati\n",
      "charoli\n",
      "chatpata\n",
      "chawal\n",
      "cheeselings\n",
      "chenna\n",
      "cherrie\n",
      "chhena\n",
      "chhole\n",
      "chikoo\n",
      "chiku\n",
      "chilies\n",
      "chilli\n",
      "chillies\n",
      "chironji\n",
      "choco\n",
      "chokha\n",
      "chole\n",
      "choori\n",
      "chura\n",
      "cilantro\n",
      "daal\n",
      "dabeli\n",
      "dahi\n",
      "dahibada\n",
      "dalia\n",
      "daliya\n",
      "dana\n",
      "desiccated\n",
      "dhaniya\n",
      "dhokla\n",
      "eno\n",
      "fafda\n",
      "falafel\n",
      "falhari\n",
      "faluda\n",
      "flattened\n",
      "frankie\n",
      "fruitspistachio\n",
      "frutti\n",
      "frying\n",
      "gajar\n",
      "gappe\n",
      "garam\n",
      "gatte\n",
      "gm\n",
      "gobhi\n",
      "gond\n",
      "gran\n",
      "gujarati\n",
      "gujiya\n",
      "gulab\n",
      "gulkand\n",
      "halwa\n",
      "hara\n",
      "hummus\n",
      "idli\n",
      "imli\n",
      "indian\n",
      "jalapeno\n",
      "jamun\n",
      "java\n",
      "jeera\n",
      "jeerawan\n",
      "kaale\n",
      "kabab\n",
      "kachha\n",
      "kadai\n",
      "kaddu\n",
      "kadhai\n",
      "kadhi\n",
      "kaju\n",
      "karonda\n",
      "karonde\n",
      "karounda\n",
      "kashmere\n",
      "kashmiri\n",
      "kasoori\n",
      "kasturi\n",
      "kasuri\n",
      "katira\n",
      "ke\n",
      "keri\n",
      "kevada\n",
      "kevda\n",
      "kevra\n",
      "kewada\n",
      "kewra\n",
      "khaman\n",
      "khand\n",
      "khari\n",
      "khas\n",
      "khathi\n",
      "kheel\n",
      "kheer\n",
      "khichadi\n",
      "khoya\n",
      "khurmi\n",
      "khus\n",
      "ki\n",
      "kulcha\n",
      "kulfa\n",
      "kulfi\n",
      "kuttu\n",
      "laal\n",
      "lachha\n",
      "laddoo\n",
      "lal\n",
      "lauki\n",
      "lavash\n",
      "ltr\n",
      "lychee\n",
      "maggi\n",
      "maggie\n",
      "maida\n",
      "makhana\n",
      "makka\n",
      "malai\n",
      "manchurian\n",
      "marie\n",
      "masal\n",
      "masala\n",
      "masale\n",
      "mashed\n",
      "masoor\n",
      "matar\n",
      "matari\n",
      "mava\n",
      "mawa\n",
      "meetha\n",
      "meethi\n",
      "methi\n",
      "milkshake\n",
      "mirch\n",
      "mirchi\n",
      "mishri\n",
      "mitha\n",
      "mixing\n",
      "monaco\n",
      "moong\n",
      "mordhan\n",
      "moyan\n",
      "mozzarella\n",
      "multi\n",
      "multigrain\n",
      "mutthee\n",
      "mysore\n",
      "naan\n",
      "nachni\n",
      "nachos\n",
      "namkeen\n",
      "needed\n",
      "nescafe\n",
      "nigella\n",
      "niggela\n",
      "nimbu\n",
      "nonstick\n",
      "nylone\n",
      "oregano\n",
      "pakoda\n",
      "pakora\n",
      "panch\n",
      "paneer\n",
      "pani\n",
      "panna\n",
      "papad\n",
      "papadi\n",
      "papads\n",
      "papdi\n",
      "parwal\n",
      "pasta\n",
      "pav\n",
      "pavbhaji\n",
      "pcs\n",
      "pinich\n",
      "pista\n",
      "pistacho\n",
      "podi\n",
      "pomagranate\n",
      "poori\n",
      "powde\n",
      "prmoi\n",
      "processed\n",
      "pudla\n",
      "pulav\n",
      "puri\n",
      "rabri\n",
      "ragda\n",
      "ragi\n",
      "rai\n",
      "raita\n",
      "rajasthani\n",
      "rajgira\n",
      "rajma\n",
      "ramphal\n",
      "rasabali\n",
      "rasagulla\n",
      "rasam\n",
      "rasgulla\n",
      "rava\n",
      "required\n",
      "rooh\n",
      "roohafza\n",
      "roti\n",
      "saag\n",
      "sabji\n",
      "sabudana\n",
      "saff\n",
      "salsa\n",
      "sama\n",
      "samak\n",
      "sambhar\n",
      "samosa\n",
      "sarso\n",
      "sarson\n",
      "sattu\n",
      "saunf\n",
      "saunth\n",
      "schezwan\n",
      "sendha\n",
      "sev\n",
      "sharbat\n",
      "shimla\n",
      "singhara\n",
      "sitafal\n",
      "sooji\n",
      "soyabean\n",
      "sp\n",
      "sugarcane\n",
      "suhaga\n",
      "tadka\n",
      "tandoori\n",
      "tava\n",
      "tinda\n",
      "to1\n",
      "toor\n",
      "urad\n",
      "vada\n",
      "vadi\n",
      "veg\n",
      "veggies\n",
      "vegs\n",
      "yogurt\n",
      "¼\n",
      "½\n",
      "¾\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from langdetect import detect\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download necessary corpora (only needed once)\n",
    "#nltk.download('words')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "# English words set\n",
    "english_vocab = set(words.words())\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Common quantity/measurement units\n",
    "units = {\n",
    "    \"g\", \"gram\", \"grams\", \"kg\", \"ml\", \"l\", \"tsp\", \"tbsp\", \"cup\", \"cups\", \"oz\", \"pound\", \"pinch\",\n",
    "    \"teaspoon\", \"teaspoons\", \"tablespoon\", \"tablespoons\", \"litre\", \"litres\", \"millilitre\", \"millilitres\",\n",
    "    \"inch\", \"inches\", \"clove\", \"cloves\", \"slice\", \"slices\", \"can\", \"cans\", \"bottle\", \"bottles\",\n",
    "    \"packet\", \"packets\", \"piece\", \"pieces\"\n",
    "}\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_excel(\"output_with_ingredients.xlsx\")\n",
    "\n",
    "# Combine all ingredient strings into one\n",
    "all_ingredients = \" \".join(df[\"ingredients\"].dropna().astype(str).tolist())\n",
    "\n",
    "# Extract tokens (words)\n",
    "tokens = re.findall(r'\\b\\w+\\b', all_ingredients)\n",
    "\n",
    "non_english_words = set()\n",
    "\n",
    "for word in tokens:\n",
    "    word_lower = word.lower()\n",
    "\n",
    "    # Skip numbers, units, or words starting with digits\n",
    "    if (word_lower.isdigit() or\n",
    "        re.match(r'^\\d', word_lower) or\n",
    "        word_lower in units):\n",
    "        continue\n",
    "\n",
    "    # Lemmatize the word to its singular/base form\n",
    "    lemma = lemmatizer.lemmatize(word_lower)\n",
    "\n",
    "    # Skip if it's an English word (after lemmatizing)\n",
    "    if lemma in english_vocab:\n",
    "        continue\n",
    "\n",
    "    # Detect and include only non-English words\n",
    "    try:\n",
    "        if detect(word_lower) != 'en':\n",
    "            non_english_words.add(word_lower)\n",
    "    except:\n",
    "        # If language detection fails, include if it's non-ASCII\n",
    "        if not word_lower.isascii():\n",
    "            non_english_words.add(word_lower)\n",
    "\n",
    "# Output the final result\n",
    "print(\"Non-English / Hindi-like words:\")\n",
    "for word in sorted(non_english_words):\n",
    "    print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
